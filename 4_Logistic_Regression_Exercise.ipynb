{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercise\n",
    "\n",
    "Now it's your turn to implement logistic regression on a new data set. For this purpose we use the Titanic Dataset. It includes personal information of all passengers on the Titanic as well as they survived the sinking of the Titanic or died.\n",
    "\n",
    "Here’s the **Data Dictionary** of the dataset:\n",
    "\n",
    "- PassengerID: type should be integers\n",
    "\n",
    "- Survived: survived or not\n",
    "\n",
    "- Pclass: class of Travel of every passenger\n",
    "\n",
    "- Name: the name of the passenger\n",
    "\n",
    "- Sex: gender\n",
    "\n",
    "- Age: age of passengers\n",
    "\n",
    "- SibSp: No. of siblings/spouse aboard\n",
    "\n",
    "- Parch: No. of parent/child aboard\n",
    "\n",
    "- Ticket: Ticket number\n",
    "\n",
    "- Fare: what Prices they paid\n",
    "\n",
    "- Cabin: cabin number\n",
    "\n",
    "- Embarked: the port in which a passenger has embarked.\n",
    "\n",
    "        - C: Cherbourg , S: Southampton , Q: Queenstown\n",
    "\n",
    "\n",
    "You will find the data in the data folder (it's a zip folder, so you first have to unzip it).\n",
    "\n",
    "\n",
    "## What you should do:\n",
    "\n",
    "- conduct a brief EDA to become familiar with the data\n",
    "- use Logistic Regression to predict if a passenger died or not\n",
    "\n",
    "## How to do it:\n",
    "\n",
    "Time is short, so aim for the simplest viable product first:\n",
    "1. Load the data\n",
    "\n",
    "2. Separate features and target \n",
    "\n",
    "3. Split the data in train and test\n",
    "\n",
    "3. Get a quick overview of the train data\n",
    "\n",
    "4. Agree on a classification metric for the task \n",
    "\n",
    "5. Create a simple heuristic/educated guess for the classification first. This is called a \"baseline model\". It is used to compare more complex models later (in this case: logistic regression). You as a data scientist want to prove how much your work/ML could improve the business metric, therefore you need a baseline model for comparison. In some cases you want to improve on an already existing model in your company which would be your baseline model then. In other cases, there are typical baseline models used in the specific field. For other tasks, you have to come up with a simple but meaningful idea, how to classify the data based on your business understanding (EDA). A baseline model should follow Occam’s Razor principle: \"A simple model is the best model\". \n",
    "    - Example of a baseline model: \n",
    "    If the task is to classify cats and dogs, a baseline model could be: We classify every animal as cat if its weight < 5 kg, otherwise the animal is classified as a dog. (The value of 5 kg is an educated guess, based on our business understanding/EDA.) \n",
    "\n",
    "6. use one or two already numerical features to create a simple first model\n",
    "    -  did it even beat your base model?\n",
    "\n",
    "7. Now you can go through the data science lifecycle again and again:\n",
    "    - clean the data better\n",
    "\n",
    "    - get more insights with EDA\n",
    "\n",
    "    - add more features\n",
    "\n",
    "    - do feature engineering \n",
    "    \n",
    "    and check if your work improves your model further!\n",
    "\n",
    "8. Stop whenever time is up or you cannot improve your model any further.\n",
    "\n",
    "This repo a solution to this problem. If you want to compare your final result with the result of this repo solution, choose **25** as random seed and a test size of 30% for your train test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cabin.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp   \n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000  \\\n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex = df.Sex.map({'male':1, 'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Parch'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#individual boxplots to see the distribution of the features\n",
    "sns.boxplot(x=df['Parch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do here:\n",
    "\n",
    "Do all of this after splitting into test and train data\n",
    "\n",
    "use SimpleImputer from sklearn to impute missing values\n",
    "\n",
    "OrdinalImputer for ordinal data (such as the embarked) or use the OneHotEncoder to map them with dummy variables\n",
    "\n",
    "### drop columns/values:\n",
    "\n",
    "drop columns: 'Name' , ('Cabin'), 'Ticket'\n",
    "\n",
    "drop values NaN: 'Embarked'\n",
    "\n",
    "impute/drop values NaN: 'Age'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X to be the columns of df without 'Cabin' and 'Survived'\n",
    "X = df.drop(columns=['Survived', 'Cabin', 'Name', 'Ticket', 'PassengerId'])\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation, Encoding and dropping\n",
    "\n",
    "F.e.: SimpleImpter, OneHotEncoder, .drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" df.Cabin.unique()\\n# so what we could do here is to cluster the cabin values into A, B, C, D, E, F ,G and T and NaN\\n# and then use that as a feature this is the only way to do it\\ndf['Cabin'] = df['Cabin'].apply(lambda x: str(x)[0])\\n\\n# count the sum of the unique values in the Cabin column \\ndf['Cabin'].value_counts()\\n# make this a categorical feature so that we can use it in our model\\ndf = pd.get_dummies(df, columns=['Cabin'], drop_first=True)\\n\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' df.Cabin.unique()\n",
    "# so what we could do here is to cluster the cabin values into A, B, C, D, E, F ,G and T and NaN\n",
    "# and then use that as a feature this is the only way to do it\n",
    "df['Cabin'] = df['Cabin'].apply(lambda x: str(x)[0])\n",
    "\n",
    "# count the sum of the unique values in the Cabin column \n",
    "df['Cabin'].value_counts()\n",
    "# make this a categorical feature so that we can use it in our model\n",
    "df = pd.get_dummies(df, columns=['Cabin'], drop_first=True)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the object feature 'Mebarked' to a categorical feature so that S =1, C=2, Q=3\n",
    "# or look at sklearn OneHotEncoder\n",
    "X = pd.get_dummies(X, columns=['Embarked'], drop_first=False, dtype = np.int64)\n",
    "# still need to drop the nan values in Embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the age nan values\n",
    "X = X.dropna(subset=['Age'])\n",
    "y = y[X.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      714 non-null    int64  \n",
      " 1   Sex         714 non-null    int64  \n",
      " 2   Age         714 non-null    float64\n",
      " 3   SibSp       714 non-null    int64  \n",
      " 4   Parch       714 non-null    int64  \n",
      " 5   Fare        714 non-null    float64\n",
      " 6   Embarked_C  714 non-null    int64  \n",
      " 7   Embarked_Q  714 non-null    int64  \n",
      " 8   Embarked_S  714 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 55.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/Documents/week5_new/logistic-regression/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg =LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = log_reg.predict(X_train)\n",
    "y_pred_test = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108581436077058\n",
      "0.7482517482517482\n",
      "0.6603773584905661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        87\n",
      "           1       0.70      0.62      0.66        56\n",
      "\n",
      "    accuracy                           0.75       143\n",
      "   macro avg       0.74      0.73      0.73       143\n",
      "weighted avg       0.75      0.75      0.75       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test the accuracy of the model\n",
    "confusion_matrix(y_train, y_pred_train)\n",
    "#give the accuracy score and the r2 score\n",
    "print(log_reg.score(X_train, y_train))\n",
    "print(log_reg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "#f1 score\n",
    "print(f1_score(y_test, y_pred_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to improve:\n",
    "\n",
    "1. Imputing the missing values of the Age column: f.e. use the PClass value to calculate the mean values of the passengers in the classes, then write a function which imputes the corresponding mean age for the passengers\n",
    "\n",
    "2. Plotting the correlations of the features AND the target: if there are some highly correlating ones, drop one of them AND construct a baseline model (f.e. just a prediction with the feature \"sex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
